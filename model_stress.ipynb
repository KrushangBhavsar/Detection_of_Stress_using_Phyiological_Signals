{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model_stress.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "b__HeqHJKbtR"
      },
      "source": [
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from torch.utils.data import Dataset\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "\n",
        "class get_dataset(Dataset):\n",
        "    def __init__(self, dataframe):\n",
        "        self.dataframe = dataframe.drop('subject', axis=1)\n",
        "        self.labels = self.dataframe['label'].values\n",
        "        self.dataframe.drop('label', axis=1, inplace=True)\n",
        "        \n",
        "    def __getitem__(self, idx):\n",
        "        x = self.dataframe.iloc[idx].values\n",
        "        y = self.labels[idx]\n",
        "        return torch.Tensor(x), y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "#LOSO(Leave-one-subject-out) Cross Validation\n",
        "feats =   ['BVP_mean', 'BVP_std', 'BVP_min', 'BVP_max',\n",
        "           'EDA_phasic_mean', 'EDA_phasic_std', 'EDA_phasic_min', 'EDA_phasic_max', 'EDA_smna_mean',\n",
        "           'EDA_smna_std', 'EDA_smna_min', 'EDA_smna_max', 'EDA_tonic_mean',\n",
        "           'EDA_tonic_std', 'EDA_tonic_min', 'EDA_tonic_max', 'Resp_mean',\n",
        "           'Resp_std', 'Resp_min', 'Resp_max', 'TEMP_mean', 'TEMP_std', 'TEMP_min',\n",
        "           'TEMP_max', 'TEMP_slope', 'BVP_peak_freq', 'age', 'height',\n",
        "           'weight','subject', 'label']\n",
        "layer_1_dim = len(feats) -2\n",
        "print(layer_1_dim)\n",
        "\n",
        "# Load Data with Batch Sizes\n",
        "def data_loader(df, subject_id, train_batch_size=25, test_batch_size=5):\n",
        "    #df = pd.read_csv('data/m14_merged.csv', index_col=0)[feats]\n",
        "\n",
        "    train_df = df[ df['subject'] != subject_id].reset_index(drop=True)\n",
        "    test_df = df[ df['subject'] == subject_id].reset_index(drop=True)\n",
        "    \n",
        "    train_dset = get_dataset(train_df)\n",
        "    test_dset = get-dataset(test_df)\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(train_dset, batch_size=train_batch_size, shuffle=True)\n",
        "    test_loader = torch.utils.data.DataLoader(test_dset, batch_size=test_batch_size)\n",
        "    \n",
        "    return train_loader, test_loader\n",
        "\n",
        "# Neural Net Architecture\n",
        "class StressNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(StressNet, self).__init__()\n",
        "        self.fc = nn.Sequential(\n",
        "                        nn.Linear(29, 128),                        \n",
        "                        nn.ReLU(),\n",
        "                        nn.Linear(128, 256),                        \n",
        "                        nn.ReLU(),\n",
        "                        nn.Linear(256, 2),                        \n",
        "                        nn.LogSoftmax(dim=1))\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return self.fc(x)\n",
        "\n",
        "\n",
        "#Model Training\n",
        "def train(model, optimizer, train_loader, validation_loader):\n",
        "    history = {'train_loss': {}, 'train_acc': {}, 'valid_loss': {}, 'valid_acc': {}}\n",
        "    #\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        # Train:   \n",
        "        total = 0\n",
        "        correct = 0\n",
        "        trainlosses = []\n",
        "\n",
        "        for batch_index, (images, labels) in enumerate(train_loader):\n",
        "\n",
        "            # Send to GPU (device)\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(images.float())\n",
        "\n",
        "            # Loss\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Backward and optimize\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            trainlosses.append(loss.item())\n",
        "\n",
        "            # Compute accuracy\n",
        "            _, argmax = torch.max(outputs, 1)\n",
        "            correct += (labels == argmax).sum().item() #.mean()\n",
        "            total += len(labels)\n",
        "\n",
        "        history['train_loss'][epoch] = np.mean(trainlosses) \n",
        "        history['train_acc'][epoch] = correct/total \n",
        "\n",
        "        if epoch % 10 == 0:\n",
        "            with torch.no_grad():\n",
        "\n",
        "                losses = []\n",
        "                total = 0\n",
        "                correct = 0\n",
        "\n",
        "                for images, labels in validation_loader:\n",
        "                    # \n",
        "                    images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "                    # Forward pass\n",
        "                    outputs = model(images.float())\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # Compute accuracy\n",
        "                    _, argmax = torch.max(outputs, 1)\n",
        "                    correct += (labels == argmax).sum().item() #.mean()\n",
        "                    total += len(labels)\n",
        "\n",
        "                    losses.append(loss.item())\n",
        "                    \n",
        "                history['valid_acc'][epoch] = np.round(correct/total, 3)\n",
        "                history['valid_loss'][epoch] = np.mean(losses)\n",
        "\n",
        "                print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {np.mean(losses):.4}, Acc: {correct/total:.2}')\n",
        "                \n",
        "    return history\n",
        "\n",
        "# Model Testing\n",
        "def test(model, validation_loader):\n",
        "    print('Evaluating model...')\n",
        "    # Test\n",
        "    model.eval()\n",
        "\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    testlosses = []\n",
        "    correct_labels = []\n",
        "    predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for batch_index, (images, labels) in enumerate(validation_loader):\n",
        "            # Send to GPU (device)\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(images.float())\n",
        "\n",
        "            # Loss\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            testlosses.append(loss.item())\n",
        "\n",
        "            # Compute accuracy\n",
        "            _, argmax = torch.max(outputs, 1)\n",
        "            correct += (labels == argmax).sum().item() #.mean()\n",
        "            total += len(labels)\n",
        "\n",
        "            correct_labels.extend(labels)\n",
        "            predictions.extend(argmax)\n",
        "\n",
        "\n",
        "    test_loss = np.mean(testlosses)\n",
        "    accuracy = np.round(correct/total, 2)\n",
        "    print(f'Loss: {test_loss:.4}, Acc: {accuracy:.2}')\n",
        "    \n",
        "    y_true = [label.item() for label in correct_labels]\n",
        "    y_pred = [label.item() for label in predictions]\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    # TODO: return y true and y pred, make cm after ( use ytrue/ypred for classification report)\n",
        "    # return [y_true, y_pred, test_loss, accuracy]\n",
        "    return cm, test_loss, accuracy\n",
        "\n",
        "# Change the label three class to binary\n",
        "def change_label(label):\n",
        "    if label == 0 or label == 1:\n",
        "        return 0\n",
        "    else:\n",
        "        return 1\n",
        "\n",
        "# Call Change Label    \n",
        "def call_change_label(df):\n",
        "  df['label'] = df['label'].apply(change_label)\n",
        "  return df['label']\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    #Get csv and Subject List\n",
        "    df = pd.read_csv('data/stress.csv', index_col=0)\n",
        "    subject_id_list = df['subject'].unique()\n",
        "    df.head()\n",
        "    # Get Features\n",
        "    df = df[feats]\n",
        "    df['label'] = call_change_label(df)\n",
        "    train_batch_size = 25\n",
        "    test_batch_size = 5\n",
        "\n",
        "    # Learning Rate\n",
        "    learning_rate = 5e-3\n",
        "\n",
        "    # Device\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # Number of Epochs\n",
        "    num_epochs = 100\n",
        "\n",
        "    # Loss and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "    histories = []\n",
        "    confusion_matrices = []\n",
        "    test_losses = []\n",
        "    test_accs = []\n",
        "    \n",
        "    #Get Subject-wise Accuracy\n",
        "    for _ in subject_id_list:\n",
        "        print('\\nSubject: ', _)\n",
        "        model = StressNet().to(device)\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "        \n",
        "        train_loader, test_loader = data_loader(df, _)\n",
        "        \n",
        "        history = train(model, optimizer, train_loader, test_loader)\n",
        "        histories.append(history)\n",
        "        \n",
        "        cm, test_loss, test_acc = test(model, test_loader)\n",
        "        test_losses.append(test_loss)\n",
        "        test_accs.append(test_acc)\n",
        "        confusion_matrices.append(cm)\n",
        "    \n",
        "    #Final Accuracy of Model\n",
        "    print(\"Final Accuracy\")  \n",
        "    print(\"Test Accuracy: \",np.mean(test_accs))\n",
        "    # Test Loss\n",
        "    print(\"Validation Loss: \",np.mean(test_losses))\n",
        "  \n",
        "    print(\"Count of Stres and Non-stress \")\n",
        "    print(df['label'].value_counts())\n",
        "\n",
        "    # Plot Test Accuracy   \n",
        "    plt.figure(figsize=(14, 6))\n",
        "    plt.title('Testing Accuracy')\n",
        "    sns.barplot(x=subject_id_list, y=test_accs)\n",
        "    # Plot Validation Loss  \n",
        "    plt.figure(figsize=(14, 3))\n",
        "    plt.title('Testing Loss')\n",
        "    sns.barplot(x=subject_id_list, y=test_losses)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}