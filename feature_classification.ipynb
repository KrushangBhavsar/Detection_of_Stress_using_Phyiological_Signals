{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "feature_classification.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZG_HSiUIgJr"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import confusion_matrix  \n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Feature Classification\n",
        "def feature_classification(path,num_ngh):\n",
        "    #Read csv    \n",
        "    df = pd.read_csv(path, index_col=0)\n",
        "    \n",
        "    #Drop index\n",
        "    X = df.drop('label', axis=1).values\n",
        "    \n",
        "    #Get label\n",
        "    y = df['label'].values\n",
        "    \n",
        "    #Seperating Training and Testing Data    \n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify = y)  \n",
        "    \n",
        "    #Setup arrays to store training and test accuracies    \n",
        "    neighbors = np.arange(1, 57)    \n",
        "    train_accuracy =np.empty(len(neighbors))\n",
        "    test_accuracy = np.empty(len(neighbors))\n",
        "\n",
        "    for i,k in enumerate(neighbors):\n",
        "        #Setup a knn classifier with k neighbors\n",
        "        k1 = num_ngh\n",
        "        \n",
        "        knn = KNeighborsClassifier(n_neighbors=k)    \n",
        "        \n",
        "        #Fit the model\n",
        "        knn.fit(X_train, y_train)    \n",
        "        \n",
        "        #Compute accuracy on the training set\n",
        "        train_accuracy[i] = knn.score(X_train, y_train)\n",
        "    \n",
        "        #Compute accuracy on the test set\n",
        "        test_accuracy[i] = knn.score(X_test, y_test)    \n",
        "    \n",
        "    #Classifier\n",
        "    knn1 = KNeighborsClassifier(n_neighbors=k1)\n",
        "    \n",
        "    #Fit Classifier Data    \n",
        "    knn1.fit(X_train,y_train)\n",
        "    print(knn1.fit)    \n",
        "    knn1.score(X_test,y_test)\n",
        "\n",
        "    y_pred = knn1.predict(X_test)\n",
        "    \n",
        "    #Compute and Print Confusion Matrix \n",
        "    confusion_matrix(y_test,y_pred)\n",
        "    cm = confusion_matrix(y_test, y_pred)  \n",
        "    print(cm)  \n",
        "    \n",
        "    #Compute and Print Accuracy\n",
        "    print('Accuracy' + str(accuracy_score(y_test, y_pred)))\n",
        "    return neighbors,test_accuracy,train_accuracy\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    #Path to Get csv\n",
        "    path = 'data/stress.csv'\n",
        "    \n",
        "    #Number of Neighbours\n",
        "    num_ngh = 7    \n",
        "    \n",
        "    clf = feature_classification(path,num_ngh)    \n",
        "    neighbors,test_accuracy,train_accuracy = clf[0],clf[1],clf[2]\n",
        "    \n",
        "    #Plotting result of Classifier\n",
        "    plt.title('k-NN Varying number of neighbors')\n",
        "    plt.plot(neighbors, test_accuracy, label='Testing Accuracy')\n",
        "    plt.plot(neighbors, train_accuracy, label='Training accuracy')\n",
        "    plt.legend()\n",
        "    plt.xlabel('Number of neighbors')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}